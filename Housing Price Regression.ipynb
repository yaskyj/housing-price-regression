{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>...</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>730.500000</td>\n",
       "      <td>56.897260</td>\n",
       "      <td>57.445890</td>\n",
       "      <td>10516.828082</td>\n",
       "      <td>6.099315</td>\n",
       "      <td>5.575342</td>\n",
       "      <td>1971.267808</td>\n",
       "      <td>1984.865753</td>\n",
       "      <td>103.111644</td>\n",
       "      <td>443.639726</td>\n",
       "      <td>...</td>\n",
       "      <td>94.244521</td>\n",
       "      <td>46.660274</td>\n",
       "      <td>21.954110</td>\n",
       "      <td>3.409589</td>\n",
       "      <td>15.060959</td>\n",
       "      <td>2.758904</td>\n",
       "      <td>43.489041</td>\n",
       "      <td>6.321918</td>\n",
       "      <td>2007.815753</td>\n",
       "      <td>180921.195890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>421.610009</td>\n",
       "      <td>42.300571</td>\n",
       "      <td>34.960241</td>\n",
       "      <td>9981.264932</td>\n",
       "      <td>1.382997</td>\n",
       "      <td>1.112799</td>\n",
       "      <td>30.202904</td>\n",
       "      <td>20.645407</td>\n",
       "      <td>180.734517</td>\n",
       "      <td>456.098091</td>\n",
       "      <td>...</td>\n",
       "      <td>125.338794</td>\n",
       "      <td>66.256028</td>\n",
       "      <td>61.119149</td>\n",
       "      <td>29.317331</td>\n",
       "      <td>55.757415</td>\n",
       "      <td>40.177307</td>\n",
       "      <td>496.123024</td>\n",
       "      <td>2.703626</td>\n",
       "      <td>1.328095</td>\n",
       "      <td>79442.502883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1300.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1872.000000</td>\n",
       "      <td>1950.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2006.000000</td>\n",
       "      <td>34900.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>365.750000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>7553.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1954.000000</td>\n",
       "      <td>1967.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2007.000000</td>\n",
       "      <td>129975.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>730.500000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>9478.500000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1973.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>383.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2008.000000</td>\n",
       "      <td>163000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1095.250000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>11601.500000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2004.000000</td>\n",
       "      <td>164.250000</td>\n",
       "      <td>712.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2009.000000</td>\n",
       "      <td>214000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1460.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>313.000000</td>\n",
       "      <td>215245.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>5644.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>857.000000</td>\n",
       "      <td>547.000000</td>\n",
       "      <td>552.000000</td>\n",
       "      <td>508.000000</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>738.000000</td>\n",
       "      <td>15500.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>755000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Id   MSSubClass  LotFrontage        LotArea  OverallQual  \\\n",
       "count  1460.000000  1460.000000  1460.000000    1460.000000  1460.000000   \n",
       "mean    730.500000    56.897260    57.445890   10516.828082     6.099315   \n",
       "std     421.610009    42.300571    34.960241    9981.264932     1.382997   \n",
       "min       1.000000    20.000000    -1.000000    1300.000000     1.000000   \n",
       "25%     365.750000    20.000000    42.000000    7553.500000     5.000000   \n",
       "50%     730.500000    50.000000    63.000000    9478.500000     6.000000   \n",
       "75%    1095.250000    70.000000    79.000000   11601.500000     7.000000   \n",
       "max    1460.000000   190.000000   313.000000  215245.000000    10.000000   \n",
       "\n",
       "       OverallCond    YearBuilt  YearRemodAdd   MasVnrArea   BsmtFinSF1  \\\n",
       "count  1460.000000  1460.000000   1460.000000  1460.000000  1460.000000   \n",
       "mean      5.575342  1971.267808   1984.865753   103.111644   443.639726   \n",
       "std       1.112799    30.202904     20.645407   180.734517   456.098091   \n",
       "min       1.000000  1872.000000   1950.000000    -1.000000     0.000000   \n",
       "25%       5.000000  1954.000000   1967.000000     0.000000     0.000000   \n",
       "50%       5.000000  1973.000000   1994.000000     0.000000   383.500000   \n",
       "75%       6.000000  2000.000000   2004.000000   164.250000   712.250000   \n",
       "max       9.000000  2010.000000   2010.000000  1600.000000  5644.000000   \n",
       "\n",
       "           ...         WoodDeckSF  OpenPorchSF  EnclosedPorch    3SsnPorch  \\\n",
       "count      ...        1460.000000  1460.000000    1460.000000  1460.000000   \n",
       "mean       ...          94.244521    46.660274      21.954110     3.409589   \n",
       "std        ...         125.338794    66.256028      61.119149    29.317331   \n",
       "min        ...           0.000000     0.000000       0.000000     0.000000   \n",
       "25%        ...           0.000000     0.000000       0.000000     0.000000   \n",
       "50%        ...           0.000000    25.000000       0.000000     0.000000   \n",
       "75%        ...         168.000000    68.000000       0.000000     0.000000   \n",
       "max        ...         857.000000   547.000000     552.000000   508.000000   \n",
       "\n",
       "       ScreenPorch     PoolArea       MiscVal       MoSold       YrSold  \\\n",
       "count  1460.000000  1460.000000   1460.000000  1460.000000  1460.000000   \n",
       "mean     15.060959     2.758904     43.489041     6.321918  2007.815753   \n",
       "std      55.757415    40.177307    496.123024     2.703626     1.328095   \n",
       "min       0.000000     0.000000      0.000000     1.000000  2006.000000   \n",
       "25%       0.000000     0.000000      0.000000     5.000000  2007.000000   \n",
       "50%       0.000000     0.000000      0.000000     6.000000  2008.000000   \n",
       "75%       0.000000     0.000000      0.000000     8.000000  2009.000000   \n",
       "max     480.000000   738.000000  15500.000000    12.000000  2010.000000   \n",
       "\n",
       "           SalePrice  \n",
       "count    1460.000000  \n",
       "mean   180921.195890  \n",
       "std     79442.502883  \n",
       "min     34900.000000  \n",
       "25%    129975.000000  \n",
       "50%    163000.000000  \n",
       "75%    214000.000000  \n",
       "max    755000.000000  \n",
       "\n",
       "[8 rows x 38 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cats = ['Alley', 'BldgType', 'BsmtCond', 'BsmtExposure', \n",
    "        'BsmtFinType1', 'BsmtFinType2', 'BsmtQual', 'CentralAir',\n",
    "        'Condition1', 'Condition2', 'Electrical', 'ExterCond', \n",
    "        'Exterior1st', 'Exterior2nd', 'ExterQual', 'Fence', \n",
    "        'FireplaceQu', 'Foundation', 'Functional', 'GarageCond', \n",
    "        'GarageFinish', 'GarageQual', 'GarageType', 'Heating', \n",
    "        'HeatingQC', 'HouseStyle', 'KitchenQual', 'LandContour', \n",
    "        'LandSlope', 'LotConfig', 'LotShape', 'MasVnrType', \n",
    "        'MiscFeature', 'MoSold', 'MSSubClass', 'MSZoning', \n",
    "        'Neighborhood', 'PavedDrive', 'PoolQC', 'RoofMatl', 'RoofStyle', \n",
    "        'SaleCondition', 'SaleType', 'Street', 'Utilities']\n",
    "nums = ['GarageYrBlt', 'LotFrontage', 'MasVnrArea', '1stFlrSF', \n",
    "        '2ndFlrSF', '3SsnPorch', 'BedroomAbvGr', 'BsmtFinSF1', \n",
    "        'BsmtFinSF2', 'BsmtFullBath', 'BsmtHalfBath', \n",
    "        'BsmtUnfSF', 'EnclosedPorch', 'Fireplaces', 'FullBath', \n",
    "        'GarageArea', 'GarageCars', 'GrLivArea', 'HalfBath', \n",
    "        'KitchenAbvGr', 'LotArea', 'LowQualFinSF', 'MiscVal', \n",
    "        'OpenPorchSF', 'OverallCond', 'OverallQual', 'PoolArea', \n",
    "        'ScreenPorch', 'TotalBsmtSF', 'TotRmsAbvGrd', \n",
    "        'WoodDeckSF', 'YearBuilt', 'YearRemodAdd', 'YrSold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "dv = DictVectorizer().fit(train[cats].T.to_dict().values())\n",
    "cat_matrix = dv.transform(train[cats].T.to_dict().values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "data_matrix = hstack([cat_matrix, train[nums]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = test.fillna(-1)\n",
    "test_cat_matrix = dv.transform(test[cats].T.to_dict().values())\n",
    "test_data_matrix = hstack([test_cat_matrix, test[nums]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import xgboost. as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
      "[CV] n_estimators=50 .................................................\n",
      "[CV] n_estimators=50 .................................................\n",
      "[CV] n_estimators=50 .................................................\n",
      "[CV] n_estimators=50 .................................................\n",
      "[CV] .................................. n_estimators=50, total=   0.3s\n",
      "[CV] n_estimators=50 .................................................\n",
      "[CV] .................................. n_estimators=50, total=   0.3s\n",
      "[CV] n_estimators=100 ................................................\n",
      "[CV] .................................. n_estimators=50, total=   0.3s\n",
      "[CV] n_estimators=100 ................................................\n",
      "[CV] .................................. n_estimators=50, total=   0.4s\n",
      "[CV] n_estimators=100 ................................................\n",
      "[CV] .................................. n_estimators=50, total=   0.4s\n",
      "[CV] n_estimators=100 ................................................\n",
      "[CV] ................................. n_estimators=100, total=   0.6s\n",
      "[CV] n_estimators=100 ................................................\n",
      "[CV] ................................. n_estimators=100, total=   0.6s\n",
      "[CV] n_estimators=150 ................................................\n",
      "[CV] ................................. n_estimators=100, total=   0.6s\n",
      "[CV] n_estimators=150 ................................................\n",
      "[CV] ................................. n_estimators=100, total=   0.6s\n",
      "[CV] n_estimators=150 ................................................\n",
      "[CV] ................................. n_estimators=100, total=   0.6s\n",
      "[CV] n_estimators=150 ................................................\n",
      "[CV] ................................. n_estimators=150, total=   0.7s\n",
      "[CV] ................................. n_estimators=150, total=   0.8s\n",
      "[CV] n_estimators=150 ................................................\n",
      "[CV] n_estimators=200 ................................................\n",
      "[CV] ................................. n_estimators=150, total=   0.8s\n",
      "[CV] n_estimators=200 ................................................\n",
      "[CV] ................................. n_estimators=150, total=   0.7s\n",
      "[CV] n_estimators=200 ................................................\n",
      "[CV] ................................. n_estimators=150, total=   0.8s\n",
      "[CV] n_estimators=200 ................................................\n",
      "[CV] ................................. n_estimators=200, total=   1.0s\n",
      "[CV] n_estimators=200 ................................................\n",
      "[CV] ................................. n_estimators=200, total=   1.0s\n",
      "[CV] n_estimators=250 ................................................\n",
      "[CV] ................................. n_estimators=200, total=   0.9s\n",
      "[CV] n_estimators=250 ................................................\n",
      "[CV] ................................. n_estimators=200, total=   0.9s\n",
      "[CV] n_estimators=250 ................................................\n",
      "[CV] ................................. n_estimators=200, total=   1.0s\n",
      "[CV] n_estimators=250 ................................................\n",
      "[CV] ................................. n_estimators=250, total=   1.2s\n",
      "[CV] n_estimators=250 ................................................\n",
      "[CV] ................................. n_estimators=250, total=   1.3s\n",
      "[CV] n_estimators=300 ................................................\n",
      "[CV] ................................. n_estimators=250, total=   1.4s\n",
      "[CV] n_estimators=300 ................................................\n",
      "[CV] ................................. n_estimators=250, total=   1.4s\n",
      "[CV] n_estimators=300 ................................................\n",
      "[CV] ................................. n_estimators=250, total=   1.4s\n",
      "[CV] n_estimators=300 ................................................\n",
      "[CV] ................................. n_estimators=300, total=   1.6s\n",
      "[CV] n_estimators=300 ................................................\n",
      "[CV] ................................. n_estimators=300, total=   1.7s\n",
      "[CV] n_estimators=350 ................................................\n",
      "[CV] ................................. n_estimators=300, total=   1.5s\n",
      "[CV] n_estimators=350 ................................................\n",
      "[CV] ................................. n_estimators=300, total=   1.5s\n",
      "[CV] n_estimators=350 ................................................\n",
      "[CV] ................................. n_estimators=300, total=   1.5s\n",
      "[CV] n_estimators=350 ................................................\n",
      "[CV] ................................. n_estimators=350, total=   1.6s\n",
      "[CV] n_estimators=350 ................................................\n",
      "[CV] ................................. n_estimators=350, total=   1.6s\n",
      "[CV] ................................. n_estimators=350, total=   1.6s\n",
      "[CV] ................................. n_estimators=350, total=   1.4s\n",
      "[CV] ................................. n_estimators=350, total=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  35 out of  35 | elapsed:   10.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -672923339.713921 using {'n_estimators': 350}\n",
      "-797570526.934801 (189575716.296216) with: {'n_estimators': 50}\n",
      "-705930113.553256 (189378930.933201) with: {'n_estimators': 100}\n",
      "-689555644.210138 (192262910.911084) with: {'n_estimators': 150}\n",
      "-682832988.596768 (193485497.107621) with: {'n_estimators': 200}\n",
      "-676550055.332540 (191835184.248101) with: {'n_estimators': 250}\n",
      "-674370870.390834 (190402451.989070) with: {'n_estimators': 300}\n",
      "-672923339.713921 (192954200.729594) with: {'n_estimators': 350}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x118448090>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEXCAYAAAC6baP3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWS5OHGZmlosTh5mZ5eLEYWZmufwfSMMj3b/HUTQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1188a9c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "boost = xgb.XGBRegressor()\n",
    "\n",
    "n_estimators = range(50, 400, 50)\n",
    "tuned_parameters = dict(n_estimators=n_estimators)\n",
    "grid = GridSearchCV(boost, tuned_parameters, cv=5, scoring='neg_mean_squared_error', n_jobs=-1, verbose=2)\n",
    "grid.fit(data_matrix, train['SalePrice'])\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid.best_score_, grid.best_params_))\n",
    "means = grid.cv_results_['mean_test_score']\n",
    "stds = grid.cv_results_['std_test_score']\n",
    "params = grid.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "# plot\n",
    "plt.errorbar(n_estimators, means, yerr=stds) \n",
    "plt.title(\"XGBoost n_estimators vs Log Loss\") \n",
    "plt.xlabel('n_estimators')\n",
    "plt.ylabel('Log Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "boost = xgb.XGBRegressor(n_estimators=350)\n",
    "boost = boost.fit(data_matrix, train['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_preds = boost.predict(data_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9462.83177974\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "print mean_squared_error(train['SalePrice'], train_preds)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = boost.predict(test_data_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['Id'] = test.Id\n",
    "submission['SalePrice'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv('submission_xgb.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures()\n",
    "poly_matrix = poly.fit_transform(data_matrix.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
      "[CV] n_estimators=50 .................................................\n",
      "[CV] n_estimators=50 .................................................\n",
      "[CV] n_estimators=50 .................................................\n",
      "[CV] n_estimators=50 .................................................\n",
      "[CV] .................................. n_estimators=50, total= 1.6min\n",
      "[CV] n_estimators=50 .................................................\n",
      "[CV] .................................. n_estimators=50, total= 1.6min\n",
      "[CV] n_estimators=100 ................................................\n",
      "[CV] .................................. n_estimators=50, total= 1.6min\n",
      "[CV] n_estimators=100 ................................................\n",
      "[CV] .................................. n_estimators=50, total= 1.6min\n",
      "[CV] n_estimators=100 ................................................\n",
      "[CV] .................................. n_estimators=50, total= 1.6min\n",
      "[CV] n_estimators=100 ................................................\n",
      "[CV] ................................. n_estimators=100, total= 3.0min\n",
      "[CV] n_estimators=100 ................................................\n",
      "[CV] ................................. n_estimators=100, total= 3.0min\n",
      "[CV] n_estimators=150 ................................................\n",
      "[CV] ................................. n_estimators=100, total= 3.0min\n",
      "[CV] n_estimators=150 ................................................\n",
      "[CV] ................................. n_estimators=100, total= 3.0min\n",
      "[CV] n_estimators=150 ................................................\n",
      "[CV] ................................. n_estimators=100, total= 3.1min\n",
      "[CV] n_estimators=150 ................................................\n",
      "[CV] ................................. n_estimators=150, total= 4.5min\n",
      "[CV] n_estimators=150 ................................................\n",
      "[CV] ................................. n_estimators=150, total= 4.5min\n",
      "[CV] n_estimators=200 ................................................\n",
      "[CV] ................................. n_estimators=150, total= 4.5min\n",
      "[CV] n_estimators=200 ................................................\n",
      "[CV] ................................. n_estimators=150, total= 4.4min\n",
      "[CV] n_estimators=200 ................................................\n",
      "[CV] ................................. n_estimators=150, total= 4.4min\n",
      "[CV] n_estimators=200 ................................................\n",
      "[CV] ................................. n_estimators=200, total= 5.9min\n",
      "[CV] n_estimators=200 ................................................\n",
      "[CV] ................................. n_estimators=200, total= 5.9min\n",
      "[CV] n_estimators=250 ................................................\n",
      "[CV] ................................. n_estimators=200, total= 5.9min\n",
      "[CV] n_estimators=250 ................................................\n",
      "[CV] ................................. n_estimators=200, total= 5.9min\n",
      "[CV] n_estimators=250 ................................................\n",
      "[CV] ................................. n_estimators=200, total= 5.9min\n",
      "[CV] n_estimators=250 ................................................\n",
      "[CV] ................................. n_estimators=250, total= 7.3min\n",
      "[CV] n_estimators=250 ................................................\n",
      "[CV] ................................. n_estimators=250, total= 7.3min\n",
      "[CV] n_estimators=300 ................................................\n",
      "[CV] ................................. n_estimators=250, total= 7.3min\n",
      "[CV] n_estimators=300 ................................................\n",
      "[CV] ................................. n_estimators=250, total= 7.3min\n",
      "[CV] n_estimators=300 ................................................\n",
      "[CV] ................................. n_estimators=250, total= 7.3min\n",
      "[CV] n_estimators=300 ................................................\n",
      "[CV] ................................. n_estimators=300, total= 8.8min\n",
      "[CV] n_estimators=300 ................................................\n",
      "[CV] ................................. n_estimators=300, total= 8.8min\n",
      "[CV] n_estimators=350 ................................................\n",
      "[CV] ................................. n_estimators=300, total= 8.8min\n",
      "[CV] n_estimators=350 ................................................\n",
      "[CV] ................................. n_estimators=300, total= 8.8min\n",
      "[CV] n_estimators=350 ................................................\n",
      "[CV] ................................. n_estimators=300, total= 8.9min\n",
      "[CV] n_estimators=350 ................................................\n",
      "[CV] ................................. n_estimators=350, total=10.3min\n",
      "[CV] n_estimators=350 ................................................\n",
      "[CV] ................................. n_estimators=350, total=10.6min\n",
      "[CV] ................................. n_estimators=350, total=10.4min\n",
      "[CV] ................................. n_estimators=350, total= 9.4min\n",
      "[CV] ................................. n_estimators=350, total= 8.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  35 out of  35 | elapsed: 54.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -775668857.694446 using {'n_estimators': 350}\n",
      "-845513782.733167 (263374756.065435) with: {'n_estimators': 50}\n",
      "-796050114.857896 (246113385.258724) with: {'n_estimators': 100}\n",
      "-789245509.757389 (243050889.307853) with: {'n_estimators': 150}\n",
      "-784186835.704886 (237514195.042055) with: {'n_estimators': 200}\n",
      "-778468043.230780 (233399326.330222) with: {'n_estimators': 250}\n",
      "-776405423.497006 (230464890.716748) with: {'n_estimators': 300}\n",
      "-775668857.694446 (229071840.637852) with: {'n_estimators': 350}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x11c6e0610>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEXCAYAAAC6baP3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1182bf450>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "boost = xgb.XGBRegressor()\n",
    "\n",
    "n_estimators = range(50, 400, 50)\n",
    "tuned_parameters = dict(n_estimators=n_estimators)\n",
    "grid = GridSearchCV(boost, tuned_parameters, cv=5, scoring='neg_mean_squared_error', n_jobs=-1, verbose=2)\n",
    "grid.fit(poly_matrix, train['SalePrice'])\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid.best_score_, grid.best_params_))\n",
    "means = grid.cv_results_['mean_test_score']\n",
    "stds = grid.cv_results_['std_test_score']\n",
    "params = grid.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "# plot\n",
    "plt.errorbar(n_estimators, means, yerr=stds) \n",
    "plt.title(\"XGBoost n_estimators vs Mean Squared Error\") \n",
    "plt.xlabel('n_estimators')\n",
    "plt.ylabel('Mean Squared Error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = test.fillna(-1)\n",
    "test_cat_matrix = dv.transform(test[cats].T.to_dict().values())\n",
    "test_data_matrix = hstack([test_cat_matrix, test[nums]])\n",
    "test_poly = poly.transform(test_data_matrix.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "boost = xgb.XGBRegressor(n_estimators=350)\n",
    "boost = boost.fit(poly_matrix, train['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_preds = boost.predict(poly_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6681.83185759\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "print mean_squared_error(train['SalePrice'], train_preds)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = boost.predict(test_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['Id'] = test.Id\n",
    "submission['SalePrice'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv('submission_xgb.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV] min_samples_split=5, n_estimators=10 ............................\n",
      "[CV] min_samples_split=5, n_estimators=10 ............................\n",
      "[CV] min_samples_split=5, n_estimators=10 ............................\n",
      "[CV] min_samples_split=5, n_estimators=10 ............................\n",
      "[CV] ............. min_samples_split=5, n_estimators=10, total=   1.0s\n",
      "[CV] min_samples_split=5, n_estimators=10 ............................\n",
      "[CV] ............. min_samples_split=5, n_estimators=10, total=   1.1s\n",
      "[CV] ............. min_samples_split=5, n_estimators=10, total=   1.1s\n",
      "[CV] min_samples_split=5, n_estimators=100 ...........................\n",
      "[CV] min_samples_split=5, n_estimators=100 ...........................\n",
      "[CV] ............. min_samples_split=5, n_estimators=10, total=   1.1s\n",
      "[CV] min_samples_split=5, n_estimators=100 ...........................\n",
      "[CV] ............. min_samples_split=5, n_estimators=10, total=   1.1s\n",
      "[CV] min_samples_split=5, n_estimators=100 ...........................\n",
      "[CV] ............ min_samples_split=5, n_estimators=100, total=  10.0s\n",
      "[CV] min_samples_split=5, n_estimators=100 ...........................\n",
      "[CV] ............ min_samples_split=5, n_estimators=100, total=  10.1s\n",
      "[CV] min_samples_split=5, n_estimators=1000 ..........................\n",
      "[CV] ............ min_samples_split=5, n_estimators=100, total=  10.1s\n",
      "[CV] min_samples_split=5, n_estimators=1000 ..........................\n",
      "[CV] ............ min_samples_split=5, n_estimators=100, total=  10.2s\n",
      "[CV] min_samples_split=5, n_estimators=1000 ..........................\n",
      "[CV] ............ min_samples_split=5, n_estimators=100, total=  11.5s\n",
      "[CV] min_samples_split=5, n_estimators=1000 ..........................\n",
      "[CV] ........... min_samples_split=5, n_estimators=1000, total= 1.9min\n",
      "[CV] min_samples_split=5, n_estimators=1000 ..........................\n",
      "[CV] ........... min_samples_split=5, n_estimators=1000, total= 1.9min\n",
      "[CV] min_samples_split=10, n_estimators=10 ...........................\n",
      "[CV] ............ min_samples_split=10, n_estimators=10, total=   0.8s\n",
      "[CV] min_samples_split=10, n_estimators=10 ...........................\n",
      "[CV] ........... min_samples_split=5, n_estimators=1000, total= 1.9min\n",
      "[CV] min_samples_split=10, n_estimators=10 ...........................\n",
      "[CV] ............ min_samples_split=10, n_estimators=10, total=   0.8s\n",
      "[CV] min_samples_split=10, n_estimators=10 ...........................\n",
      "[CV] ............ min_samples_split=10, n_estimators=10, total=   0.8s\n",
      "[CV] min_samples_split=10, n_estimators=10 ...........................\n",
      "[CV] ............ min_samples_split=10, n_estimators=10, total=   0.9s\n",
      "[CV] min_samples_split=10, n_estimators=100 ..........................\n",
      "[CV] ............ min_samples_split=10, n_estimators=10, total=   0.9s\n",
      "[CV] min_samples_split=10, n_estimators=100 ..........................\n",
      "[CV] ........... min_samples_split=5, n_estimators=1000, total= 1.9min\n",
      "[CV] min_samples_split=10, n_estimators=100 ..........................\n",
      "[CV] ........... min_samples_split=10, n_estimators=100, total=   9.3s\n",
      "[CV] min_samples_split=10, n_estimators=100 ..........................\n",
      "[CV] ........... min_samples_split=10, n_estimators=100, total=   9.3s\n",
      "[CV] min_samples_split=10, n_estimators=100 ..........................\n",
      "[CV] ........... min_samples_split=10, n_estimators=100, total=   9.8s\n",
      "[CV] min_samples_split=10, n_estimators=1000 .........................\n",
      "[CV] ........... min_samples_split=10, n_estimators=100, total=   9.7s\n",
      "[CV] min_samples_split=10, n_estimators=1000 .........................\n",
      "[CV] ........... min_samples_split=10, n_estimators=100, total=   9.5s\n",
      "[CV] min_samples_split=10, n_estimators=1000 .........................\n",
      "[CV] .......... min_samples_split=10, n_estimators=1000, total= 1.5min\n",
      "[CV] min_samples_split=10, n_estimators=1000 .........................\n",
      "[CV] .......... min_samples_split=10, n_estimators=1000, total= 1.5min\n",
      "[CV] min_samples_split=10, n_estimators=1000 .........................\n",
      "[CV] .......... min_samples_split=10, n_estimators=1000, total= 1.5min\n",
      "[CV] min_samples_split=20, n_estimators=10 ...........................\n",
      "[CV] ............ min_samples_split=20, n_estimators=10, total=   0.6s\n",
      "[CV] min_samples_split=20, n_estimators=10 ...........................\n",
      "[CV] ............ min_samples_split=20, n_estimators=10, total=   0.6s\n",
      "[CV] min_samples_split=20, n_estimators=10 ...........................\n",
      "[CV] ............ min_samples_split=20, n_estimators=10, total=   0.6s\n",
      "[CV] min_samples_split=20, n_estimators=10 ...........................\n",
      "[CV] ............ min_samples_split=20, n_estimators=10, total=   0.5s\n",
      "[CV] min_samples_split=20, n_estimators=10 ...........................\n",
      "[CV] ........... min_samples_split=5, n_estimators=1000, total= 1.9min\n",
      "[CV] min_samples_split=20, n_estimators=100 ..........................\n",
      "[CV] ............ min_samples_split=20, n_estimators=10, total=   0.5s\n",
      "[CV] min_samples_split=20, n_estimators=100 ..........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  4.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........... min_samples_split=20, n_estimators=100, total=   5.2s\n",
      "[CV] min_samples_split=20, n_estimators=100 ..........................\n",
      "[CV] ........... min_samples_split=20, n_estimators=100, total=   5.2s\n",
      "[CV] min_samples_split=20, n_estimators=100 ..........................\n",
      "[CV] ........... min_samples_split=20, n_estimators=100, total=   5.4s\n",
      "[CV] min_samples_split=20, n_estimators=100 ..........................\n",
      "[CV] ........... min_samples_split=20, n_estimators=100, total=   5.4s\n",
      "[CV] min_samples_split=20, n_estimators=1000 .........................\n",
      "[CV] ........... min_samples_split=20, n_estimators=100, total=   5.5s\n",
      "[CV] min_samples_split=20, n_estimators=1000 .........................\n",
      "[CV] .......... min_samples_split=20, n_estimators=1000, total=  53.4s\n",
      "[CV] min_samples_split=20, n_estimators=1000 .........................\n",
      "[CV] .......... min_samples_split=20, n_estimators=1000, total=  53.2s\n",
      "[CV] min_samples_split=20, n_estimators=1000 .........................\n",
      "[CV] .......... min_samples_split=10, n_estimators=1000, total= 1.4min\n",
      "[CV] min_samples_split=20, n_estimators=1000 .........................\n",
      "[CV] .......... min_samples_split=10, n_estimators=1000, total= 1.4min\n",
      "[CV] .......... min_samples_split=20, n_estimators=1000, total=  49.4s\n",
      "[CV] .......... min_samples_split=20, n_estimators=1000, total=  47.8s\n",
      "[CV] .......... min_samples_split=20, n_estimators=1000, total=  44.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:  6.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=5, error_score='raise',\n",
      "       estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
      "       fit_params=None, iid=True, n_jobs=-1,\n",
      "       param_grid=[{'n_estimators': [10, 100, 1000], 'min_samples_split': [5, 10, 20]}],\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
      "       scoring='neg_mean_squared_error', verbose=2)\n",
      "-900071013.75\n",
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=1, min_samples_split=5,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "tuned_parameters = [{'n_estimators': [10, 100, 1000], 'min_samples_split': [5, 10, 20]}]\n",
    "grid = GridSearchCV(RandomForestRegressor(), tuned_parameters, cv=5, scoring='neg_mean_squared_error', n_jobs=-1, verbose=2)\n",
    "grid.fit(data_matrix, train['SalePrice'])\n",
    "print(grid)\n",
    "# summarize the results of the grid search\n",
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "forest = RandomForestRegressor(min_samples_split=5, n_estimators=100, n_jobs=-1)\n",
    "forest = forest.fit(data_matrix, train['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_preds = forest.predict(data_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12649.2817084\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "print mean_squared_error(train['SalePrice'], train_preds)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = forest.predict(test_data_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['Id'] = test.Id\n",
    "submission['SalePrice'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv('submission_forest.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
