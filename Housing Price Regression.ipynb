{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>...</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>730.500000</td>\n",
       "      <td>56.897260</td>\n",
       "      <td>57.445890</td>\n",
       "      <td>10516.828082</td>\n",
       "      <td>6.099315</td>\n",
       "      <td>5.575342</td>\n",
       "      <td>1971.267808</td>\n",
       "      <td>1984.865753</td>\n",
       "      <td>103.111644</td>\n",
       "      <td>443.639726</td>\n",
       "      <td>...</td>\n",
       "      <td>94.244521</td>\n",
       "      <td>46.660274</td>\n",
       "      <td>21.954110</td>\n",
       "      <td>3.409589</td>\n",
       "      <td>15.060959</td>\n",
       "      <td>2.758904</td>\n",
       "      <td>43.489041</td>\n",
       "      <td>6.321918</td>\n",
       "      <td>2007.815753</td>\n",
       "      <td>180921.195890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>421.610009</td>\n",
       "      <td>42.300571</td>\n",
       "      <td>34.960241</td>\n",
       "      <td>9981.264932</td>\n",
       "      <td>1.382997</td>\n",
       "      <td>1.112799</td>\n",
       "      <td>30.202904</td>\n",
       "      <td>20.645407</td>\n",
       "      <td>180.734517</td>\n",
       "      <td>456.098091</td>\n",
       "      <td>...</td>\n",
       "      <td>125.338794</td>\n",
       "      <td>66.256028</td>\n",
       "      <td>61.119149</td>\n",
       "      <td>29.317331</td>\n",
       "      <td>55.757415</td>\n",
       "      <td>40.177307</td>\n",
       "      <td>496.123024</td>\n",
       "      <td>2.703626</td>\n",
       "      <td>1.328095</td>\n",
       "      <td>79442.502883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1300.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1872.000000</td>\n",
       "      <td>1950.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2006.000000</td>\n",
       "      <td>34900.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>365.750000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>7553.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1954.000000</td>\n",
       "      <td>1967.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2007.000000</td>\n",
       "      <td>129975.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>730.500000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>9478.500000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1973.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>383.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2008.000000</td>\n",
       "      <td>163000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1095.250000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>11601.500000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2004.000000</td>\n",
       "      <td>164.250000</td>\n",
       "      <td>712.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2009.000000</td>\n",
       "      <td>214000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1460.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>313.000000</td>\n",
       "      <td>215245.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>5644.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>857.000000</td>\n",
       "      <td>547.000000</td>\n",
       "      <td>552.000000</td>\n",
       "      <td>508.000000</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>738.000000</td>\n",
       "      <td>15500.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>755000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Id   MSSubClass  LotFrontage        LotArea  OverallQual  \\\n",
       "count  1460.000000  1460.000000  1460.000000    1460.000000  1460.000000   \n",
       "mean    730.500000    56.897260    57.445890   10516.828082     6.099315   \n",
       "std     421.610009    42.300571    34.960241    9981.264932     1.382997   \n",
       "min       1.000000    20.000000    -1.000000    1300.000000     1.000000   \n",
       "25%     365.750000    20.000000    42.000000    7553.500000     5.000000   \n",
       "50%     730.500000    50.000000    63.000000    9478.500000     6.000000   \n",
       "75%    1095.250000    70.000000    79.000000   11601.500000     7.000000   \n",
       "max    1460.000000   190.000000   313.000000  215245.000000    10.000000   \n",
       "\n",
       "       OverallCond    YearBuilt  YearRemodAdd   MasVnrArea   BsmtFinSF1  \\\n",
       "count  1460.000000  1460.000000   1460.000000  1460.000000  1460.000000   \n",
       "mean      5.575342  1971.267808   1984.865753   103.111644   443.639726   \n",
       "std       1.112799    30.202904     20.645407   180.734517   456.098091   \n",
       "min       1.000000  1872.000000   1950.000000    -1.000000     0.000000   \n",
       "25%       5.000000  1954.000000   1967.000000     0.000000     0.000000   \n",
       "50%       5.000000  1973.000000   1994.000000     0.000000   383.500000   \n",
       "75%       6.000000  2000.000000   2004.000000   164.250000   712.250000   \n",
       "max       9.000000  2010.000000   2010.000000  1600.000000  5644.000000   \n",
       "\n",
       "           ...         WoodDeckSF  OpenPorchSF  EnclosedPorch    3SsnPorch  \\\n",
       "count      ...        1460.000000  1460.000000    1460.000000  1460.000000   \n",
       "mean       ...          94.244521    46.660274      21.954110     3.409589   \n",
       "std        ...         125.338794    66.256028      61.119149    29.317331   \n",
       "min        ...           0.000000     0.000000       0.000000     0.000000   \n",
       "25%        ...           0.000000     0.000000       0.000000     0.000000   \n",
       "50%        ...           0.000000    25.000000       0.000000     0.000000   \n",
       "75%        ...         168.000000    68.000000       0.000000     0.000000   \n",
       "max        ...         857.000000   547.000000     552.000000   508.000000   \n",
       "\n",
       "       ScreenPorch     PoolArea       MiscVal       MoSold       YrSold  \\\n",
       "count  1460.000000  1460.000000   1460.000000  1460.000000  1460.000000   \n",
       "mean     15.060959     2.758904     43.489041     6.321918  2007.815753   \n",
       "std      55.757415    40.177307    496.123024     2.703626     1.328095   \n",
       "min       0.000000     0.000000      0.000000     1.000000  2006.000000   \n",
       "25%       0.000000     0.000000      0.000000     5.000000  2007.000000   \n",
       "50%       0.000000     0.000000      0.000000     6.000000  2008.000000   \n",
       "75%       0.000000     0.000000      0.000000     8.000000  2009.000000   \n",
       "max     480.000000   738.000000  15500.000000    12.000000  2010.000000   \n",
       "\n",
       "           SalePrice  \n",
       "count    1460.000000  \n",
       "mean   180921.195890  \n",
       "std     79442.502883  \n",
       "min     34900.000000  \n",
       "25%    129975.000000  \n",
       "50%    163000.000000  \n",
       "75%    214000.000000  \n",
       "max    755000.000000  \n",
       "\n",
       "[8 rows x 38 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cats = ['Alley', 'BldgType', 'BsmtCond', 'BsmtExposure', \n",
    "        'BsmtFinType1', 'BsmtFinType2', 'BsmtQual', 'CentralAir',\n",
    "        'Condition1', 'Condition2', 'Electrical', 'ExterCond', \n",
    "        'Exterior1st', 'Exterior2nd', 'ExterQual', 'Fence', \n",
    "        'FireplaceQu', 'Foundation', 'Functional', 'GarageCond', \n",
    "        'GarageFinish', 'GarageQual', 'GarageType', 'Heating', \n",
    "        'HeatingQC', 'HouseStyle', 'KitchenQual', 'LandContour', \n",
    "        'LandSlope', 'LotConfig', 'LotShape', 'MasVnrType', \n",
    "        'MiscFeature', 'MoSold', 'MSSubClass', 'MSZoning', \n",
    "        'Neighborhood', 'PavedDrive', 'PoolQC', 'RoofMatl', 'RoofStyle', \n",
    "        'SaleCondition', 'SaleType', 'Street', 'Utilities']\n",
    "nums = ['GarageYrBlt', 'LotFrontage', 'MasVnrArea', '1stFlrSF', \n",
    "        '2ndFlrSF', '3SsnPorch', 'BedroomAbvGr', 'BsmtFinSF1', \n",
    "        'BsmtFinSF2', 'BsmtFullBath', 'BsmtHalfBath', \n",
    "        'BsmtUnfSF', 'EnclosedPorch', 'Fireplaces', 'FullBath', \n",
    "        'GarageArea', 'GarageCars', 'GrLivArea', 'HalfBath', \n",
    "        'KitchenAbvGr', 'LotArea', 'LowQualFinSF', 'MiscVal', \n",
    "        'OpenPorchSF', 'OverallCond', 'OverallQual', 'PoolArea', \n",
    "        'ScreenPorch', 'TotalBsmtSF', 'TotRmsAbvGrd', \n",
    "        'WoodDeckSF', 'YearBuilt', 'YearRemodAdd', 'YrSold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "dv = DictVectorizer().fit(train[cats].T.to_dict().values())\n",
    "cat_matrix = dv.transform(train[cats].T.to_dict().values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly_cat = PolynomialFeatures()\n",
    "poly_cat_matrix = poly_cat.fit_transform(cat_matrix.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "ridge = Ridge(alpha=1.0)\n",
    "ridge.fit(poly_cat_matrix, train['SalePrice'])\n",
    "ridge_preds = ridge.predict(poly_cat_matrix)\n",
    "ridge_preds = [[i] for i in ridge_preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "data_matrix = hstack([ridge_preds, train[nums]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import xgboost. as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures()\n",
    "poly_matrix = poly.fit_transform(data_matrix.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
      "[CV] n_estimators=50 .................................................\n",
      "[CV] n_estimators=50 .................................................\n",
      "[CV] n_estimators=50 .................................................\n",
      "[CV] n_estimators=50 .................................................\n",
      "[CV] .................................. n_estimators=50, total=   2.0s\n",
      "[CV] n_estimators=50 .................................................\n",
      "[CV] .................................. n_estimators=50, total=   2.1s\n",
      "[CV] n_estimators=100 ................................................\n",
      "[CV] .................................. n_estimators=50, total=   2.3s\n",
      "[CV] n_estimators=100 ................................................\n",
      "[CV] .................................. n_estimators=50, total=   2.2s\n",
      "[CV] n_estimators=100 ................................................\n",
      "[CV] .................................. n_estimators=50, total=   2.1s\n",
      "[CV] n_estimators=100 ................................................\n",
      "[CV] ................................. n_estimators=100, total=   4.1s\n",
      "[CV] n_estimators=100 ................................................\n",
      "[CV] ................................. n_estimators=100, total=   4.1s\n",
      "[CV] ................................. n_estimators=100, total=   4.1s\n",
      "[CV] n_estimators=150 ................................................\n",
      "[CV] n_estimators=150 ................................................\n",
      "[CV] ................................. n_estimators=100, total=   4.1s\n",
      "[CV] n_estimators=150 ................................................\n",
      "[CV] ................................. n_estimators=100, total=   4.0s\n",
      "[CV] n_estimators=150 ................................................\n",
      "[CV] ................................. n_estimators=150, total=   6.0s\n",
      "[CV] n_estimators=150 ................................................\n",
      "[CV] ................................. n_estimators=150, total=   6.1s\n",
      "[CV] n_estimators=200 ................................................\n",
      "[CV] ................................. n_estimators=150, total=   6.1s\n",
      "[CV] n_estimators=200 ................................................\n",
      "[CV] ................................. n_estimators=150, total=   5.9s\n",
      "[CV] n_estimators=200 ................................................\n",
      "[CV] ................................. n_estimators=150, total=   6.1s\n",
      "[CV] n_estimators=200 ................................................\n",
      "[CV] ................................. n_estimators=200, total=   8.6s\n",
      "[CV] n_estimators=200 ................................................\n",
      "[CV] ................................. n_estimators=200, total=   8.8s\n",
      "[CV] n_estimators=250 ................................................\n",
      "[CV] ................................. n_estimators=200, total=   8.7s\n",
      "[CV] n_estimators=250 ................................................\n",
      "[CV] ................................. n_estimators=200, total=   8.2s\n",
      "[CV] n_estimators=250 ................................................\n",
      "[CV] ................................. n_estimators=200, total=   7.6s\n",
      "[CV] n_estimators=250 ................................................\n",
      "[CV] ................................. n_estimators=250, total=   9.6s\n",
      "[CV] n_estimators=250 ................................................\n",
      "[CV] ................................. n_estimators=250, total=   9.8s\n",
      "[CV] n_estimators=300 ................................................\n",
      "[CV] ................................. n_estimators=250, total=   9.8s\n",
      "[CV] n_estimators=300 ................................................\n",
      "[CV] ................................. n_estimators=250, total=   9.8s\n",
      "[CV] n_estimators=300 ................................................\n",
      "[CV] ................................. n_estimators=250, total=  10.0s\n",
      "[CV] n_estimators=300 ................................................\n",
      "[CV] ................................. n_estimators=300, total=  12.0s\n",
      "[CV] n_estimators=300 ................................................\n",
      "[CV] ................................. n_estimators=300, total=  12.1s\n",
      "[CV] n_estimators=350 ................................................\n",
      "[CV] ................................. n_estimators=300, total=  12.1s\n",
      "[CV] n_estimators=350 ................................................\n",
      "[CV] ................................. n_estimators=300, total=  12.1s\n",
      "[CV] n_estimators=350 ................................................\n",
      "[CV] ................................. n_estimators=300, total=  12.4s\n",
      "[CV] n_estimators=350 ................................................\n",
      "[CV] ................................. n_estimators=350, total=  15.1s\n",
      "[CV] n_estimators=350 ................................................\n",
      "[CV] ................................. n_estimators=350, total=  15.2s\n",
      "[CV] ................................. n_estimators=350, total=  14.8s\n",
      "[CV] ................................. n_estimators=350, total=  12.9s\n",
      "[CV] ................................. n_estimators=350, total=  10.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  35 out of  35 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -13739128.042044 using {'n_estimators': 100}\n",
      "-20031736.033177 (6177241.301585) with: {'n_estimators': 50}\n",
      "-13739128.042044 (2688626.321828) with: {'n_estimators': 100}\n",
      "-13957596.232583 (2753911.530893) with: {'n_estimators': 150}\n",
      "-14161640.989078 (2834712.762185) with: {'n_estimators': 200}\n",
      "-14333304.216760 (2922587.593025) with: {'n_estimators': 250}\n",
      "-14337449.337006 (2914981.507795) with: {'n_estimators': 300}\n",
      "-14434220.823952 (2852923.062550) with: {'n_estimators': 350}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x13dab4ad0>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEXCAYAAAC6baP3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x118977790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "boost = xgb.XGBRegressor()\n",
    "\n",
    "n_estimators = range(50, 400, 50)\n",
    "tuned_parameters = dict(n_estimators=n_estimators)\n",
    "grid = GridSearchCV(boost, tuned_parameters, cv=5, scoring='neg_mean_squared_error', n_jobs=-1, verbose=2)\n",
    "grid.fit(poly_matrix, train['SalePrice'])\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid.best_score_, grid.best_params_))\n",
    "means = grid.cv_results_['mean_test_score']\n",
    "stds = grid.cv_results_['std_test_score']\n",
    "params = grid.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "# plot\n",
    "plt.errorbar(n_estimators, means, yerr=stds) \n",
    "plt.title(\"XGBoost n_estimators vs Mean Squared Error\") \n",
    "plt.xlabel('n_estimators')\n",
    "plt.ylabel('Mean Squared Error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.56 s, sys: 9.65 ms, total: 2.57 s\n",
      "Wall time: 2.57 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "boost = xgb.XGBRegressor(n_estimators=100)\n",
    "boost = boost.fit(poly_matrix, train['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_preds = boost.predict(poly_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2158.96374583\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "print mean_squared_error(train['SalePrice'], train_preds)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = test.fillna(-1)\n",
    "test_cat_matrix = dv.transform(test[cats].T.to_dict().values())\n",
    "test_poly_cat_matrix = poly_cat.transform(test_cat_matrix.toarray())\n",
    "\n",
    "test_ridge_preds = ridge.predict(test_poly_cat_matrix)\n",
    "test_ridge_preds = [[i] for i in test_ridge_preds]\n",
    "\n",
    "test_data_matrix = hstack([test_ridge_preds, test[nums]])\n",
    "test_poly = poly.transform(test_data_matrix.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = boost.predict(test_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['Id'] = test.Id\n",
    "submission['SalePrice'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv('submission_xgb.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV] min_samples_split=5, n_estimators=10 ............................\n",
      "[CV] min_samples_split=5, n_estimators=10 ............................\n",
      "[CV] min_samples_split=5, n_estimators=10 ............................\n",
      "[CV] min_samples_split=5, n_estimators=10 ............................\n",
      "[CV] ............. min_samples_split=5, n_estimators=10, total=   1.0s\n",
      "[CV] min_samples_split=5, n_estimators=10 ............................\n",
      "[CV] ............. min_samples_split=5, n_estimators=10, total=   1.1s\n",
      "[CV] ............. min_samples_split=5, n_estimators=10, total=   1.1s\n",
      "[CV] min_samples_split=5, n_estimators=100 ...........................\n",
      "[CV] min_samples_split=5, n_estimators=100 ...........................\n",
      "[CV] ............. min_samples_split=5, n_estimators=10, total=   1.1s\n",
      "[CV] min_samples_split=5, n_estimators=100 ...........................\n",
      "[CV] ............. min_samples_split=5, n_estimators=10, total=   1.1s\n",
      "[CV] min_samples_split=5, n_estimators=100 ...........................\n",
      "[CV] ............ min_samples_split=5, n_estimators=100, total=  10.0s\n",
      "[CV] min_samples_split=5, n_estimators=100 ...........................\n",
      "[CV] ............ min_samples_split=5, n_estimators=100, total=  10.1s\n",
      "[CV] min_samples_split=5, n_estimators=1000 ..........................\n",
      "[CV] ............ min_samples_split=5, n_estimators=100, total=  10.1s\n",
      "[CV] min_samples_split=5, n_estimators=1000 ..........................\n",
      "[CV] ............ min_samples_split=5, n_estimators=100, total=  10.2s\n",
      "[CV] min_samples_split=5, n_estimators=1000 ..........................\n",
      "[CV] ............ min_samples_split=5, n_estimators=100, total=  11.5s\n",
      "[CV] min_samples_split=5, n_estimators=1000 ..........................\n",
      "[CV] ........... min_samples_split=5, n_estimators=1000, total= 1.9min\n",
      "[CV] min_samples_split=5, n_estimators=1000 ..........................\n",
      "[CV] ........... min_samples_split=5, n_estimators=1000, total= 1.9min\n",
      "[CV] min_samples_split=10, n_estimators=10 ...........................\n",
      "[CV] ............ min_samples_split=10, n_estimators=10, total=   0.8s\n",
      "[CV] min_samples_split=10, n_estimators=10 ...........................\n",
      "[CV] ........... min_samples_split=5, n_estimators=1000, total= 1.9min\n",
      "[CV] min_samples_split=10, n_estimators=10 ...........................\n",
      "[CV] ............ min_samples_split=10, n_estimators=10, total=   0.8s\n",
      "[CV] min_samples_split=10, n_estimators=10 ...........................\n",
      "[CV] ............ min_samples_split=10, n_estimators=10, total=   0.8s\n",
      "[CV] min_samples_split=10, n_estimators=10 ...........................\n",
      "[CV] ............ min_samples_split=10, n_estimators=10, total=   0.9s\n",
      "[CV] min_samples_split=10, n_estimators=100 ..........................\n",
      "[CV] ............ min_samples_split=10, n_estimators=10, total=   0.9s\n",
      "[CV] min_samples_split=10, n_estimators=100 ..........................\n",
      "[CV] ........... min_samples_split=5, n_estimators=1000, total= 1.9min\n",
      "[CV] min_samples_split=10, n_estimators=100 ..........................\n",
      "[CV] ........... min_samples_split=10, n_estimators=100, total=   9.3s\n",
      "[CV] min_samples_split=10, n_estimators=100 ..........................\n",
      "[CV] ........... min_samples_split=10, n_estimators=100, total=   9.3s\n",
      "[CV] min_samples_split=10, n_estimators=100 ..........................\n",
      "[CV] ........... min_samples_split=10, n_estimators=100, total=   9.8s\n",
      "[CV] min_samples_split=10, n_estimators=1000 .........................\n",
      "[CV] ........... min_samples_split=10, n_estimators=100, total=   9.7s\n",
      "[CV] min_samples_split=10, n_estimators=1000 .........................\n",
      "[CV] ........... min_samples_split=10, n_estimators=100, total=   9.5s\n",
      "[CV] min_samples_split=10, n_estimators=1000 .........................\n",
      "[CV] .......... min_samples_split=10, n_estimators=1000, total= 1.5min\n",
      "[CV] min_samples_split=10, n_estimators=1000 .........................\n",
      "[CV] .......... min_samples_split=10, n_estimators=1000, total= 1.5min\n",
      "[CV] min_samples_split=10, n_estimators=1000 .........................\n",
      "[CV] .......... min_samples_split=10, n_estimators=1000, total= 1.5min\n",
      "[CV] min_samples_split=20, n_estimators=10 ...........................\n",
      "[CV] ............ min_samples_split=20, n_estimators=10, total=   0.6s\n",
      "[CV] min_samples_split=20, n_estimators=10 ...........................\n",
      "[CV] ............ min_samples_split=20, n_estimators=10, total=   0.6s\n",
      "[CV] min_samples_split=20, n_estimators=10 ...........................\n",
      "[CV] ............ min_samples_split=20, n_estimators=10, total=   0.6s\n",
      "[CV] min_samples_split=20, n_estimators=10 ...........................\n",
      "[CV] ............ min_samples_split=20, n_estimators=10, total=   0.5s\n",
      "[CV] min_samples_split=20, n_estimators=10 ...........................\n",
      "[CV] ........... min_samples_split=5, n_estimators=1000, total= 1.9min\n",
      "[CV] min_samples_split=20, n_estimators=100 ..........................\n",
      "[CV] ............ min_samples_split=20, n_estimators=10, total=   0.5s\n",
      "[CV] min_samples_split=20, n_estimators=100 ..........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  4.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........... min_samples_split=20, n_estimators=100, total=   5.2s\n",
      "[CV] min_samples_split=20, n_estimators=100 ..........................\n",
      "[CV] ........... min_samples_split=20, n_estimators=100, total=   5.2s\n",
      "[CV] min_samples_split=20, n_estimators=100 ..........................\n",
      "[CV] ........... min_samples_split=20, n_estimators=100, total=   5.4s\n",
      "[CV] min_samples_split=20, n_estimators=100 ..........................\n",
      "[CV] ........... min_samples_split=20, n_estimators=100, total=   5.4s\n",
      "[CV] min_samples_split=20, n_estimators=1000 .........................\n",
      "[CV] ........... min_samples_split=20, n_estimators=100, total=   5.5s\n",
      "[CV] min_samples_split=20, n_estimators=1000 .........................\n",
      "[CV] .......... min_samples_split=20, n_estimators=1000, total=  53.4s\n",
      "[CV] min_samples_split=20, n_estimators=1000 .........................\n",
      "[CV] .......... min_samples_split=20, n_estimators=1000, total=  53.2s\n",
      "[CV] min_samples_split=20, n_estimators=1000 .........................\n",
      "[CV] .......... min_samples_split=10, n_estimators=1000, total= 1.4min\n",
      "[CV] min_samples_split=20, n_estimators=1000 .........................\n",
      "[CV] .......... min_samples_split=10, n_estimators=1000, total= 1.4min\n",
      "[CV] .......... min_samples_split=20, n_estimators=1000, total=  49.4s\n",
      "[CV] .......... min_samples_split=20, n_estimators=1000, total=  47.8s\n",
      "[CV] .......... min_samples_split=20, n_estimators=1000, total=  44.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:  6.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=5, error_score='raise',\n",
      "       estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
      "       fit_params=None, iid=True, n_jobs=-1,\n",
      "       param_grid=[{'n_estimators': [10, 100, 1000], 'min_samples_split': [5, 10, 20]}],\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
      "       scoring='neg_mean_squared_error', verbose=2)\n",
      "-900071013.75\n",
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=1, min_samples_split=5,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "tuned_parameters = [{'n_estimators': [10, 100, 1000], 'min_samples_split': [5, 10, 20]}]\n",
    "grid = GridSearchCV(RandomForestRegressor(), tuned_parameters, cv=5, scoring='neg_mean_squared_error', n_jobs=-1, verbose=2)\n",
    "grid.fit(data_matrix, train['SalePrice'])\n",
    "print(grid)\n",
    "# summarize the results of the grid search\n",
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "forest = RandomForestRegressor(min_samples_split=5, n_estimators=100, n_jobs=-1)\n",
    "forest = forest.fit(data_matrix, train['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_preds = forest.predict(data_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12649.2817084\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "print mean_squared_error(train['SalePrice'], train_preds)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = forest.predict(test_data_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['Id'] = test.Id\n",
    "submission['SalePrice'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv('submission_forest.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
