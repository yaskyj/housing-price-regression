{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn import metrics\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Root Mean Squared Log Error function for GridSearch\n",
    "from sklearn.metrics import make_scorer\n",
    "def rmsle(predicted, actual):\n",
    "    assert(len(predicted) == len(actual))\n",
    "    p = np.log(np.array(predicted) + 1)\n",
    "    a = np.log(np.array(actual) + 1)\n",
    "    return (((p - a)**2).sum() / len(predicted))**0.5\n",
    "rmsle_loss = make_scorer(rmsle, greater_is_better=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Fill NAs with -1 and convert MSSubClass to strings\n",
    "### since they are integers but are actually\n",
    "### unordered categorical\n",
    "train = train.fillna(-1)\n",
    "train['MSSubClass'] = train['MSSubClass'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = [c for c in train.columns if c not in['Id','SalePrice']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cats = ['Alley', 'BldgType', 'BsmtCond', 'BsmtExposure', \n",
    "        'BsmtFinType1', 'BsmtFinType2', 'BsmtQual', 'CentralAir',\n",
    "        'Condition1', 'Condition2', 'Electrical', 'ExterCond', \n",
    "        'Exterior1st', 'Exterior2nd', 'ExterQual', 'Fence', \n",
    "        'FireplaceQu', 'Foundation', 'Functional', 'GarageCond', \n",
    "        'GarageFinish', 'GarageQual', 'GarageType', 'Heating', \n",
    "        'HeatingQC', 'HouseStyle', 'KitchenQual', 'LandContour', \n",
    "        'LandSlope', 'LotConfig', 'LotShape', 'MasVnrType', \n",
    "        'MiscFeature', 'MoSold', 'MSSubClass', 'MSZoning', \n",
    "        'Neighborhood', 'PavedDrive', 'PoolQC', 'RoofMatl', 'RoofStyle', \n",
    "        'SaleCondition', 'SaleType', 'Street', 'Utilities']\n",
    "nums = ['GarageYrBlt', 'LotFrontage', 'MasVnrArea', '1stFlrSF', \n",
    "        '2ndFlrSF', '3SsnPorch', 'BedroomAbvGr', 'BsmtFinSF1', \n",
    "        'BsmtFinSF2', 'BsmtFullBath', 'BsmtHalfBath', \n",
    "        'BsmtUnfSF', 'EnclosedPorch', 'Fireplaces', 'FullBath', \n",
    "        'GarageArea', 'GarageCars', 'GrLivArea', 'HalfBath', \n",
    "        'KitchenAbvGr', 'LotArea', 'LowQualFinSF', 'MiscVal', \n",
    "        'OpenPorchSF', 'OverallCond', 'OverallQual', 'PoolArea', \n",
    "        'ScreenPorch', 'TotalBsmtSF', 'TotRmsAbvGrd', \n",
    "        'WoodDeckSF', 'YearBuilt', 'YearRemodAdd', 'YrSold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "dv = DictVectorizer().fit(train[features].T.to_dict().values())\n",
    "data_matrix = dv.transform(train[features].T.to_dict().values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_matrix = hstack([cat_matrix, train[nums]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures()\n",
    "poly_matrix = poly.fit_transform(data_matrix.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(poly_matrix, train['SalePrice'], test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV] n_estimators=50, learning_rate=0.01, max_depth=5 ................\n",
      "[CV] n_estimators=50, learning_rate=0.01, max_depth=5 ................\n",
      "[CV] n_estimators=50, learning_rate=0.01, max_depth=5 ................\n",
      "[CV] n_estimators=50, learning_rate=0.01, max_depth=5 ................\n",
      "[CV]  n_estimators=50, learning_rate=0.01, max_depth=5, score=-0.925917728994, total= 1.9min\n",
      "[CV] n_estimators=50, learning_rate=0.01, max_depth=5 ................\n",
      "[CV]  n_estimators=50, learning_rate=0.01, max_depth=5, score=-0.926792663908, total= 1.9min\n",
      "[CV] n_estimators=50, learning_rate=0.01, max_depth=8 ................\n",
      "[CV]  n_estimators=50, learning_rate=0.01, max_depth=5, score=-0.952629809471, total= 1.9min\n",
      "[CV] n_estimators=50, learning_rate=0.01, max_depth=8 ................\n",
      "[CV]  n_estimators=50, learning_rate=0.01, max_depth=5, score=-0.944266610279, total= 1.9min\n",
      "[CV] n_estimators=50, learning_rate=0.01, max_depth=8 ................\n",
      "[CV]  n_estimators=50, learning_rate=0.01, max_depth=5, score=-0.942050783009, total= 2.0min\n",
      "[CV] n_estimators=50, learning_rate=0.01, max_depth=8 ................\n",
      "[CV]  n_estimators=50, learning_rate=0.01, max_depth=8, score=-0.952752422917, total= 2.4min\n",
      "[CV] n_estimators=50, learning_rate=0.01, max_depth=8 ................\n",
      "[CV]  n_estimators=50, learning_rate=0.01, max_depth=8, score=-0.926921572189, total= 2.5min\n",
      "[CV] n_estimators=50, learning_rate=0.1, max_depth=5 .................\n",
      "[CV]  n_estimators=50, learning_rate=0.01, max_depth=8, score=-0.927999853315, total= 2.5min\n",
      "[CV] n_estimators=50, learning_rate=0.1, max_depth=5 .................\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "boost = xgb.XGBRegressor()\n",
    "# n_estimators = [50, 100, 300, 400]\n",
    "n_estimators = [50]\n",
    "max_depth = [5, 8]\n",
    "# learning_rate = [0.0001, 0.001, 0.01, 0.1]\n",
    "learning_rate = [0.01, 0.1]\n",
    "tuned_parameters = dict(max_depth=max_depth, n_estimators=n_estimators, learning_rate=learning_rate)\n",
    "grid = GridSearchCV(boost, tuned_parameters, cv=3, scoring=rmsle_loss, n_jobs=-1, verbose=3)\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid.best_score_, grid.best_params_))\n",
    "means = grid.cv_results_['mean_test_score']\n",
    "stds = grid.cv_results_['std_test_score']\n",
    "params = grid.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot\n",
    "scores = np.array(means).reshape(len(learning_rate), len(max_depth), len(n_estimators))\n",
    "for i, value in enumerate(learning_rate):\n",
    "    plt.plot(n_estimators, scores[i][1], label='learning_rate: ' + str(value)) \n",
    "plt.legend()\n",
    "plt.xlabel('n_estimators')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "# print scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot\n",
    "scores = np.array(means).reshape(len(max_depth), len(learning_rate), len(n_estimators))\n",
    "for i, value in enumerate(max_depth):\n",
    "    plt.plot(n_estimators, scores[i][1], label='max_depth: ' + str(value)) \n",
    "plt.legend()\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('Mean Squared Error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "boost = xgb.XGBRegressor(n_estimators=400, max_depth=2, learning_rate=0.1)\n",
    "boost = boost.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "train_preds = boost.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "print mean_squared_log_error(y_test, train_preds)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = test.fillna(-1)\n",
    "test_matrix = dv.transform(test[cats].T.to_dict().values())\n",
    "test_data_matrix = hstack([test_matrix, test[nums]])\n",
    "test_poly = poly.transform(test_data_matrix.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = boost.predict(test_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['Id'] = test.Id\n",
    "submission['SalePrice'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv('submission_xgb.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
